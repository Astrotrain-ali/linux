#Hadoop
#	介绍
-	集中式
#####集中式系统用一句话概括就是：一个主机带多个终端。终端没有数据处理能力，仅负责数据的录入和输出。而运算、存储等全部在主机上进行。现在的银行系统，大部分都是这种集中式的系统，此外，在大型企业、科研单位、军队、政府等也有分布。集中式系统，主要流行于上个世纪。
#####集中式系统的最大的特点就是部署结构非常简单，底层一般采用从IBM、HP等厂商购买到的昂贵的大型主机。因此无需考虑如何对服务进行多节点的部署，也就不用考虑各节点之间的分布式协作问题。但是，由于采用单机部署。很可能带来系统大而复杂、难于维护、发生单点故障（单个点发生故障的时候会波及到整个系统或者网络，从而导致整个系统或者网络的瘫痪）、扩展性差等问题。
-	分布式系统
#####一群独立计算机集合共同对外提供服务，但是对于系统的用户来说，就像是一台计算机在提供服务一样。分布式意味着可以采用更多的普通计算机（相对于昂贵的大型机）组成分布式集群对外提供服务。计算机越多，CPU、内存、存储资源等也就越多，能够处理的并发访问量也就越大。
-	标准的分布式系统应该具有以下几个主要特征
	-	分布性：分布式系统中的多台计算机之间在空间位置上可以随意分布，系统中的多台计算机之间没有主、从之分，即没有控制整个系统的主机，也没有受控的从机。
	-	透明性：系统资源被所有计算机共享。每台计算机的用户不仅可以使用本机的资源，还可以使用本分布式系统中其他计算机的资源(包括CPU、文件、打印机等)。
	-	同一性：系统中的若干台计算机可以互相协作来完成一个共同的任务，或者说一个程序可以分布在几台计算机上并行地运行。
	-	通信性：系统中任意两台计算机都可以通过通信来交换信息。
-	分布式数据和存储
	-	大型网站常常需要处理海量数据，单台计算机往往无法提供足够的内存空间，可以对这些数据进行分布式存储。
-	分布式计算
	-	随着计算技术的发展，有些应用需要非常巨大的计算能力才能完成，如果采用集中式计算，需要耗费相当长的时间来完成。分布式计算将该应用分解成许多小的部分，分配给多台计算机进行处理。这样可以节约整体计算时间，大大提高计算效率。
-	关系型数据库， MapReduce (大规模数据批量分析)
	-	数据访问效率
#####磁盘寻址时间提高速度远远小于数据传输速率提高速度（寻址是将磁头移动到特定硬盘位置进行读写操作，这是导致硬盘操作延迟的主要原因，而传输速率取决于硬盘的带宽）。对于超大规模数据（以PB为单位）必须考虑使用其他方式。关系型数据库使用B树结构进行数据的更新查询操作，对于最大到GB的数据量，一般相对数据量较小，效果很好。但是大数据量时，B树使用排序/合并方式重建数据库以更新数据的效率远远低于MapReduce。
-	数据结构不同
	-	结构化数据：是具体既定格式的实体化数据，如XML文档或满足特定预定义格式的数据库表。这是RDBMS包括的内容。 
	-	半结构化数据比较松散，虽然可能有格式，但是经常被忽略，所以他只能作为对的一般指导。如：一张电子表格，其结构是由单元格组成的网格，但是每个单元格自身可保存任何形式的数据。 
	-	非结构化数据: 没有什么特别的内部结构，如纯文本或图像数据。
#####关系型数据使用的是结构化数据，在数据库阶段按具体类型处理数据。关系型数据的规范性非常重要，保持数据的完整性，一致性。
			

#####Hadoop是一个开源框架，使用MapReduce算法运行，Hadoop框架提供跨计算机集群的分布式存储和计算的环境，它允许在整个集群使用简单编程模型计算机的分布式环境存储并处理大数据。它的目的是从单一的服务器到上千台机器的扩展，每一个台机都可以提供本地计算和存储。
#####Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。



#####Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，则MapReduce为海量的数据提供了计算。
	
-	hadoop解决哪些问题？
	-	海量数据需要及时分析和处理
	-	海量数据需要深入分析和挖掘
	-	数据需要长期保存
-	海量数据存储的问题
	-	磁盘IO称为一种瓶颈，而非CPU资源
	-	网络带宽是一种稀缺资源
	-	硬件故障成为影响稳定的一大因素
-	hadoop架构
	-	MapReduce：编程模型，主要用来做数据分析，最大化利用CPU。
	-	HDFS：分布式文件系统，最大化利用磁盘。
	-	Hbase：Nosql数据库，Key-Value存储，最大化利用内存。
	-	hive: